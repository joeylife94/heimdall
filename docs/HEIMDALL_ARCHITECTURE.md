# ğŸ›¡ï¸ Heimdall Architecture Guide

> **"The Guardian of the Rainbow Bridge"** - Event-driven Log Processing Microservice

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#-ì‹œìŠ¤í…œ-ê°œìš”)
2. [ì•„í‚¤í…ì²˜ ì„¤ê³„](#-ì•„í‚¤í…ì²˜-ì„¤ê³„)
3. [ê¸°ìˆ  ìŠ¤íƒ](#-ê¸°ìˆ -ìŠ¤íƒ)
4. [Kafka í†µì‹  ì„¤ê³„](#-kafka-í†µì‹ -ì„¤ê³„)
5. [ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„](#-ë°ì´í„°ë² ì´ìŠ¤-ì„¤ê³„)
6. [API ì„¤ê³„](#-api-ì„¤ê³„)
7. [ë³´ì•ˆ ì•„í‚¤í…ì²˜](#-ë³´ì•ˆ-ì•„í‚¤í…ì²˜)
8. [ë°°í¬ ì „ëµ](#-ë°°í¬-ì „ëµ)

---

## ğŸ¯ ì‹œìŠ¤í…œ ê°œìš”

### Mission Statement

**Heimdall**ì€ Bifrostì˜ ë³´ì™„ ì„œë¹„ìŠ¤ë¡œ, ë‹¤ìŒ ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤:

- ğŸ“Š **ë¡œê·¸ ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬**: ë‹¤ì–‘í•œ ì†ŒìŠ¤ë¡œë¶€í„° ë¡œê·¸ ìˆ˜ì§‘
- ğŸ”„ **ì´ë²¤íŠ¸ ê¸°ë°˜ ì²˜ë¦¬**: Kafkaë¥¼ í†µí•œ ë¹„ë™ê¸° ë¡œê·¸ ì²˜ë¦¬
- ğŸ’¾ **ì¥ê¸° ì €ì¥ì†Œ**: ë¶„ì„ëœ ë¡œê·¸ì˜ ì˜êµ¬ ë³´ê´€
- ğŸ“ˆ **í†µê³„ ë° ì§‘ê³„**: ë¡œê·¸ í†µê³„, íŠ¸ë Œë“œ ë¶„ì„
- ğŸ” **ê²€ìƒ‰ ì—”ì§„**: Elasticsearch ê¸°ë°˜ ì „ë¬¸ ê²€ìƒ‰
- ğŸ“¡ **ì•Œë¦¼ ê´€ë¦¬**: ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼ ë°œì†¡

### ì‹œìŠ¤í…œ ê²½ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Bifrost Ecosystem                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚    Bifrost       â”‚         â”‚    Heimdall      â”‚        â”‚
â”‚  â”‚  (Python/AI)     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ (Java/Spring)    â”‚        â”‚
â”‚  â”‚                  â”‚  Kafka  â”‚                  â”‚        â”‚
â”‚  â”‚  - AI ë¶„ì„       â”‚         â”‚  - ë¡œê·¸ ìˆ˜ì§‘     â”‚        â”‚
â”‚  â”‚  - ì‹¤ì‹œê°„ ì²˜ë¦¬    â”‚         â”‚  - ì¥ê¸° ì €ì¥     â”‚        â”‚
â”‚  â”‚  - WebUI        â”‚         â”‚  - ê²€ìƒ‰/í†µê³„     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                              â”‚                   â”‚
â”‚         â”‚                              â”‚                   â”‚
â”‚    PostgreSQL                     PostgreSQL               â”‚
â”‚    (ë¶„ì„ ê²°ê³¼)                    (ë¡œê·¸ ì›ë³¸)              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•µì‹¬ ì„¤ê³„ ì›ì¹™

1. **ì´ë²¤íŠ¸ ê¸°ë°˜**: ëª¨ë“  ë¡œê·¸ëŠ” Kafka ì´ë²¤íŠ¸ë¡œ ì²˜ë¦¬
2. **ëŠìŠ¨í•œ ê²°í•©**: Bifrostì™€ ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜ ê°€ëŠ¥
3. **í™•ì¥ì„±**: ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥í•œ stateless ì„œë¹„ìŠ¤
4. **ë‚´ê²°í•¨ì„±**: ì¥ì•  ê²©ë¦¬ ë° ìë™ ë³µêµ¬
5. **ê´€ì°°ì„±**: ëª¨ë“  ê³„ì¸µì—ì„œ ë©”íŠ¸ë¦­ ë° íŠ¸ë ˆì´ì‹±

---

## ğŸ›ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Client Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  REST    â”‚  â”‚  gRPC    â”‚  â”‚  Kafka   â”‚                 â”‚
â”‚  â”‚  API     â”‚  â”‚  API     â”‚  â”‚ Consumer â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Application Layer (Spring Boot)                â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Controllers                                        â”‚   â”‚
â”‚  â”‚  - LogController                                    â”‚   â”‚
â”‚  â”‚  - SearchController                                 â”‚   â”‚
â”‚  â”‚  - StatisticsController                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Services (Business Logic)                          â”‚   â”‚
â”‚  â”‚  - LogIngestionService                              â”‚   â”‚
â”‚  â”‚  - LogProcessingService                             â”‚   â”‚
â”‚  â”‚  - SearchService                                    â”‚   â”‚
â”‚  â”‚  - StatisticsService                                â”‚   â”‚
â”‚  â”‚  - NotificationService                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Kafka Listeners (Event Consumers)                  â”‚   â”‚
â”‚  â”‚  - AnalysisRequestListener                          â”‚   â”‚
â”‚  â”‚  - AnalysisResultListener                           â”‚   â”‚
â”‚  â”‚  - LogIngestionListener                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data Access Layer (Spring Data JPA)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Repositories â”‚  â”‚   Entities   â”‚  â”‚  Mappers     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Infrastructure Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ PostgreSQL  â”‚  â”‚Elasticsearchâ”‚  â”‚   Kafka     â”‚        â”‚
â”‚  â”‚  (Primary)  â”‚  â”‚  (Search)   â”‚  â”‚  (Queue)    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Diagram

```
heimdall/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â”œâ”€â”€ java/
â”‚       â”‚   â””â”€â”€ com/
â”‚       â”‚       â””â”€â”€ heimdall/
â”‚       â”‚           â”œâ”€â”€ HeimdallApplication.java
â”‚       â”‚           â”‚
â”‚       â”‚           â”œâ”€â”€ config/
â”‚       â”‚           â”‚   â”œâ”€â”€ KafkaConfig.java
â”‚       â”‚           â”‚   â”œâ”€â”€ DatabaseConfig.java
â”‚       â”‚           â”‚   â”œâ”€â”€ ElasticsearchConfig.java
â”‚       â”‚           â”‚   â”œâ”€â”€ SecurityConfig.java
â”‚       â”‚           â”‚   â””â”€â”€ AsyncConfig.java
â”‚       â”‚           â”‚
â”‚       â”‚           â”œâ”€â”€ controller/
â”‚       â”‚           â”‚   â”œâ”€â”€ LogController.java
â”‚       â”‚           â”‚   â”œâ”€â”€ SearchController.java
â”‚       â”‚           â”‚   â”œâ”€â”€ StatisticsController.java
â”‚       â”‚           â”‚   â””â”€â”€ HealthController.java
â”‚       â”‚           â”‚
â”‚       â”‚           â”œâ”€â”€ service/
â”‚       â”‚           â”‚   â”œâ”€â”€ LogIngestionService.java
â”‚       â”‚           â”‚   â”œâ”€â”€ LogProcessingService.java
â”‚       â”‚           â”‚   â”œâ”€â”€ SearchService.java
â”‚       â”‚           â”‚   â”œâ”€â”€ StatisticsService.java
â”‚       â”‚           â”‚   â”œâ”€â”€ NotificationService.java
â”‚       â”‚           â”‚   â””â”€â”€ BifrostIntegrationService.java
â”‚       â”‚           â”‚
â”‚       â”‚           â”œâ”€â”€ kafka/
â”‚       â”‚           â”‚   â”œâ”€â”€ listener/
â”‚       â”‚           â”‚   â”‚   â”œâ”€â”€ AnalysisRequestListener.java
â”‚       â”‚           â”‚   â”‚   â”œâ”€â”€ AnalysisResultListener.java
â”‚       â”‚           â”‚   â”‚   â””â”€â”€ LogIngestionListener.java
â”‚       â”‚           â”‚   â”œâ”€â”€ producer/
â”‚       â”‚           â”‚   â”‚   â””â”€â”€ KafkaProducerService.java
â”‚       â”‚           â”‚   â””â”€â”€ event/
â”‚       â”‚           â”‚       â”œâ”€â”€ LogIngestionEvent.java
â”‚       â”‚           â”‚       â”œâ”€â”€ AnalysisRequestEvent.java
â”‚       â”‚           â”‚       â””â”€â”€ AnalysisResultEvent.java
â”‚       â”‚           â”‚
â”‚       â”‚           â”œâ”€â”€ repository/
â”‚       â”‚           â”‚   â”œâ”€â”€ LogEntryRepository.java
â”‚       â”‚           â”‚   â”œâ”€â”€ AnalysisResultRepository.java
â”‚       â”‚           â”‚   â”œâ”€â”€ LogStatisticsRepository.java
â”‚       â”‚           â”‚   â””â”€â”€ NotificationRepository.java
â”‚       â”‚           â”‚
â”‚       â”‚           â”œâ”€â”€ entity/
â”‚       â”‚           â”‚   â”œâ”€â”€ LogEntry.java
â”‚       â”‚           â”‚   â”œâ”€â”€ AnalysisResult.java
â”‚       â”‚           â”‚   â”œâ”€â”€ LogStatistics.java
â”‚       â”‚           â”‚   â””â”€â”€ Notification.java
â”‚       â”‚           â”‚
â”‚       â”‚           â”œâ”€â”€ dto/
â”‚       â”‚           â”‚   â”œâ”€â”€ LogIngestionRequest.java
â”‚       â”‚           â”‚   â”œâ”€â”€ LogSearchRequest.java
â”‚       â”‚           â”‚   â”œâ”€â”€ LogSearchResponse.java
â”‚       â”‚           â”‚   â””â”€â”€ StatisticsResponse.java
â”‚       â”‚           â”‚
â”‚       â”‚           â”œâ”€â”€ exception/
â”‚       â”‚           â”‚   â”œâ”€â”€ HeimdallException.java
â”‚       â”‚           â”‚   â”œâ”€â”€ LogProcessingException.java
â”‚       â”‚           â”‚   â””â”€â”€ GlobalExceptionHandler.java
â”‚       â”‚           â”‚
â”‚       â”‚           â””â”€â”€ util/
â”‚       â”‚               â”œâ”€â”€ DateTimeUtil.java
â”‚       â”‚               â””â”€â”€ HashUtil.java
â”‚       â”‚
â”‚       â””â”€â”€ resources/
â”‚           â”œâ”€â”€ application.yml
â”‚           â”œâ”€â”€ application-dev.yml
â”‚           â”œâ”€â”€ application-prod.yml
â”‚           â””â”€â”€ logback-spring.xml
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â””â”€â”€ secret.yaml
â”‚
â”œâ”€â”€ build.gradle (ë˜ëŠ” pom.xml)
â””â”€â”€ README.md
```

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

### Core Framework

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Framework** | Spring Boot | 3.2.x | ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬ |
| **Language** | Java | 17 (LTS) | í”„ë¡œê·¸ë˜ë° ì–¸ì–´ |
| **Build Tool** | Gradle | 8.x | ë¹Œë“œ ìë™í™” |

### Spring Ecosystem

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Spring Web** | Spring MVC | REST API |
| **Spring Data JPA** | Hibernate | ORM / ë°ì´í„° ì•¡ì„¸ìŠ¤ |
| **Spring Kafka** | - | Kafka í†µí•© |
| **Spring Security** | - | ì¸ì¦/ì¸ê°€ |
| **Spring Actuator** | - | í—¬ìŠ¤ì²´í¬/ë©”íŠ¸ë¦­ |
| **Spring Validation** | - | ì…ë ¥ ê²€ì¦ |

### Infrastructure

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Database** | PostgreSQL 16 | ì£¼ ë°ì´í„° ì €ì¥ì†Œ |
| **Message Queue** | Apache Kafka 3.6 | ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° |
| **Search Engine** | Elasticsearch 8.x | ì „ë¬¸ ê²€ìƒ‰ |
| **Cache** | Redis 7.x | ìºì‹± (ì„ íƒ) |
| **Monitoring** | Micrometer + Prometheus | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ |

### DevOps

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Container** | Docker | ì»¨í…Œì´ë„ˆí™” |
| **Orchestration** | Kubernetes | ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ |
| **CI/CD** | GitHub Actions | ìë™í™” íŒŒì´í”„ë¼ì¸ |

---

## ğŸ”„ Kafka í†µì‹  ì„¤ê³„

### Topic êµ¬ì¡°

```
bifrost-ecosystem/
â”œâ”€â”€ logs.ingestion         # ë¡œê·¸ ìˆ˜ì§‘ ìš”ì²­
â”œâ”€â”€ logs.processing        # ë¡œê·¸ ì „ì²˜ë¦¬ ì™„ë£Œ
â”œâ”€â”€ analysis.request       # AI ë¶„ì„ ìš”ì²­ (â†’ Bifrost)
â”œâ”€â”€ analysis.result        # AI ë¶„ì„ ê²°ê³¼ (â† Bifrost)
â”œâ”€â”€ notification.alert     # ì•Œë¦¼ ë°œì†¡
â””â”€â”€ dlq.failed            # Dead Letter Queue (ì‹¤íŒ¨)
```

### Event Schema

#### 1. logs.ingestion (Heimdall â†’ Kafka)

```json
{
  "eventId": "uuid",
  "timestamp": "2024-10-25T10:30:00Z",
  "source": "k8s-prod",
  "serviceName": "user-service",
  "environment": "production",
  "logContent": "ERROR: Connection timeout...",
  "severity": "ERROR",
  "metadata": {
    "podName": "user-service-abc123",
    "namespace": "production",
    "nodeId": "node-1"
  }
}
```

#### 2. analysis.request (Heimdall â†’ Bifrost)

```json
{
  "requestId": "uuid",
  "timestamp": "2024-10-25T10:30:05Z",
  "logId": 12345,
  "logContent": "ERROR: Connection timeout...",
  "serviceName": "user-service",
  "environment": "production",
  "analysisType": "error",
  "priority": "HIGH",
  "callbackTopic": "analysis.result",
  "correlationId": "correlation-uuid"
}
```

#### 3. analysis.result (Bifrost â†’ Heimdall)

```json
{
  "requestId": "uuid",
  "correlationId": "correlation-uuid",
  "timestamp": "2024-10-25T10:30:15Z",
  "logId": 12345,
  "analysisResult": {
    "summary": "PostgreSQL ì—°ê²° íƒ€ì„ì•„ì›ƒ ë°œìƒ",
    "rootCause": "Connection pool ê³ ê°ˆ",
    "recommendation": "max_connections ì¦ê°€ ê¶Œì¥",
    "severity": "HIGH",
    "confidence": 0.95
  },
  "bifrostAnalysisId": 456,
  "model": "mistral",
  "durationSeconds": 2.5
}
```

### Kafka Consumer ì„¤ì •

```java
@Configuration
public class KafkaConfig {
    
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, 
                   "kafka:9092");
        config.put(ConsumerConfig.GROUP_ID_CONFIG, 
                   "heimdall-consumer-group");
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, 
                   StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, 
                   StringDeserializer.class);
        
        // At-least-once ë³´ì¥
        config.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        
        // ì„±ëŠ¥ íŠœë‹
        config.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 100);
        config.put(ConsumerConfig.FETCH_MIN_BYTES_CONFIG, 1024);
        
        return new DefaultKafkaConsumerFactory<>(config);
    }
    
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> 
        kafkaListenerContainerFactory() {
        
        ConcurrentKafkaListenerContainerFactory<String, String> factory = 
            new ConcurrentKafkaListenerContainerFactory<>();
        
        factory.setConsumerFactory(consumerFactory());
        factory.setConcurrency(3); // ë³‘ë ¬ ì²˜ë¦¬
        factory.getContainerProperties()
               .setAckMode(AckMode.MANUAL_IMMEDIATE);
        
        // ì—ëŸ¬ í•¸ë“¤ë§
        factory.setCommonErrorHandler(
            new DefaultErrorHandler(
                new DeadLetterPublishingRecoverer(kafkaTemplate()),
                new FixedBackOff(1000L, 3L)
            )
        );
        
        return factory;
    }
}
```

### Kafka Producer ì„¤ì •

```java
@Service
public class KafkaProducerService {
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    public void sendAnalysisRequest(AnalysisRequestEvent event) {
        String topic = "analysis.request";
        String key = event.getLogId().toString();
        String value = objectMapper.writeValueAsString(event);
        
        ListenableFuture<SendResult<String, String>> future = 
            kafkaTemplate.send(topic, key, value);
        
        future.addCallback(
            result -> log.info("Message sent: {}", result.getRecordMetadata()),
            ex -> log.error("Failed to send message", ex)
        );
    }
}
```

### Message Flow

```
1. ë¡œê·¸ ìˆ˜ì§‘ í”Œë¡œìš°
   Client â†’ Heimdall REST API
     â†’ logs.ingestion (Kafka)
     â†’ LogIngestionListener
     â†’ PostgreSQL ì €ì¥
     â†’ analysis.request (Kafka) â†’ Bifrost

2. ë¶„ì„ ê²°ê³¼ ìˆ˜ì‹  í”Œë¡œìš°
   Bifrost â†’ analysis.result (Kafka)
     â†’ AnalysisResultListener
     â†’ PostgreSQL ì—…ë°ì´íŠ¸
     â†’ Elasticsearch ì¸ë±ì‹±
     â†’ notification.alert (ì¡°ê±´ ë§Œì¡± ì‹œ)

3. ì—ëŸ¬ ì²˜ë¦¬ í”Œë¡œìš°
   ì²˜ë¦¬ ì‹¤íŒ¨ â†’ dlq.failed (Kafka)
     â†’ DLQListener
     â†’ ì¬ì²˜ë¦¬ ë˜ëŠ” ì•Œë¦¼
```

---

## ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„

### ERD (Entity Relationship Diagram)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    log_entries      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)             â”‚
â”‚ event_id (UK)       â”‚
â”‚ timestamp           â”‚
â”‚ source              â”‚
â”‚ service_name        â”‚
â”‚ environment         â”‚
â”‚ severity            â”‚
â”‚ log_content (TEXT)  â”‚
â”‚ log_hash            â”‚
â”‚ metadata (JSONB)    â”‚
â”‚ created_at          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ 1
           â”‚
           â”‚ N
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ analysis_results    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)             â”‚
â”‚ log_id (FK)         â”‚
â”‚ bifrost_analysis_id â”‚
â”‚ request_id          â”‚
â”‚ correlation_id      â”‚
â”‚ summary             â”‚
â”‚ root_cause          â”‚
â”‚ recommendation      â”‚
â”‚ severity            â”‚
â”‚ confidence          â”‚
â”‚ model               â”‚
â”‚ duration_seconds    â”‚
â”‚ analyzed_at         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  log_statistics     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)             â”‚
â”‚ date                â”‚
â”‚ hour                â”‚
â”‚ service_name        â”‚
â”‚ environment         â”‚
â”‚ severity            â”‚
â”‚ count               â”‚
â”‚ avg_size_bytes      â”‚
â”‚ created_at          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   notifications     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)             â”‚
â”‚ log_id (FK)         â”‚
â”‚ analysis_id (FK)    â”‚
â”‚ type                â”‚
â”‚ channel             â”‚
â”‚ recipient           â”‚
â”‚ message             â”‚
â”‚ sent_at             â”‚
â”‚ status              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Schema Definition (PostgreSQL)

```sql
-- ë¡œê·¸ ì—”íŠ¸ë¦¬ í…Œì´ë¸”
CREATE TABLE log_entries (
    id BIGSERIAL PRIMARY KEY,
    event_id VARCHAR(36) UNIQUE NOT NULL,
    timestamp TIMESTAMP NOT NULL,
    source VARCHAR(100) NOT NULL,
    service_name VARCHAR(100),
    environment VARCHAR(50),
    severity VARCHAR(20) NOT NULL,
    log_content TEXT NOT NULL,
    log_hash VARCHAR(64) NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- ì¸ë±ìŠ¤
    INDEX idx_timestamp (timestamp DESC),
    INDEX idx_service_env (service_name, environment),
    INDEX idx_severity (severity),
    INDEX idx_log_hash (log_hash)
);

-- íŒŒí‹°ì…”ë‹ (ì„ íƒì )
CREATE TABLE log_entries_2024_10 PARTITION OF log_entries
    FOR VALUES FROM ('2024-10-01') TO ('2024-11-01');

-- ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
CREATE TABLE analysis_results (
    id BIGSERIAL PRIMARY KEY,
    log_id BIGINT NOT NULL REFERENCES log_entries(id),
    bifrost_analysis_id BIGINT,
    request_id VARCHAR(36) UNIQUE NOT NULL,
    correlation_id VARCHAR(36),
    summary TEXT,
    root_cause TEXT,
    recommendation TEXT,
    severity VARCHAR(20),
    confidence DECIMAL(3,2),
    model VARCHAR(100),
    duration_seconds DECIMAL(10,2),
    analyzed_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_log_id (log_id),
    INDEX idx_analyzed_at (analyzed_at DESC),
    INDEX idx_severity (severity)
);

-- ë¡œê·¸ í†µê³„ í…Œì´ë¸” (ì§‘ê³„)
CREATE TABLE log_statistics (
    id BIGSERIAL PRIMARY KEY,
    date DATE NOT NULL,
    hour SMALLINT NOT NULL,
    service_name VARCHAR(100),
    environment VARCHAR(50),
    severity VARCHAR(20),
    count INTEGER NOT NULL DEFAULT 0,
    avg_size_bytes INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE (date, hour, service_name, environment, severity),
    INDEX idx_date_hour (date, hour)
);

-- ì•Œë¦¼ í…Œì´ë¸”
CREATE TABLE notifications (
    id BIGSERIAL PRIMARY KEY,
    log_id BIGINT REFERENCES log_entries(id),
    analysis_id BIGINT REFERENCES analysis_results(id),
    type VARCHAR(50) NOT NULL,
    channel VARCHAR(50) NOT NULL,
    recipient VARCHAR(200) NOT NULL,
    message TEXT NOT NULL,
    sent_at TIMESTAMP NOT NULL,
    status VARCHAR(20) DEFAULT 'PENDING',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_sent_at (sent_at DESC),
    INDEX idx_status (status)
);
```

### JPA Entity ì˜ˆì‹œ

```java
@Entity
@Table(name = "log_entries")
@Data
@NoArgsConstructor
@AllArgsConstructor
public class LogEntry {
    
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    @Column(name = "event_id", unique = true, nullable = false, length = 36)
    private String eventId;
    
    @Column(nullable = false)
    private LocalDateTime timestamp;
    
    @Column(nullable = false, length = 100)
    private String source;
    
    @Column(name = "service_name", length = 100)
    private String serviceName;
    
    @Column(length = 50)
    private String environment;
    
    @Enumerated(EnumType.STRING)
    @Column(nullable = false, length = 20)
    private SeverityLevel severity;
    
    @Column(name = "log_content", columnDefinition = "TEXT", nullable = false)
    private String logContent;
    
    @Column(name = "log_hash", nullable = false, length = 64)
    private String logHash;
    
    @Type(JsonBinaryType.class)
    @Column(columnDefinition = "jsonb")
    private Map<String, Object> metadata;
    
    @Column(name = "created_at", nullable = false, updatable = false)
    private LocalDateTime createdAt = LocalDateTime.now();
    
    @OneToMany(mappedBy = "logEntry", cascade = CascadeType.ALL)
    private List<AnalysisResult> analysisResults;
}
```

---

## ğŸŒ API ì„¤ê³„

### REST API Endpoints

#### 1. ë¡œê·¸ ìˆ˜ì§‘ API

```
POST /api/v1/logs
Content-Type: application/json
Authorization: Bearer <token>

Request Body:
{
  "source": "k8s-prod",
  "serviceName": "user-service",
  "environment": "production",
  "severity": "ERROR",
  "logContent": "ERROR: Connection timeout to database",
  "metadata": {
    "podName": "user-service-abc123",
    "namespace": "production"
  }
}

Response (201 Created):
{
  "logId": 12345,
  "eventId": "550e8400-e29b-41d4-a716-446655440000",
  "timestamp": "2024-10-25T10:30:00Z",
  "status": "ACCEPTED",
  "analysisRequested": true
}
```

#### 2. ë¡œê·¸ ê²€ìƒ‰ API

```
GET /api/v1/logs/search
Authorization: Bearer <token>

Query Parameters:
- serviceName: string
- environment: string
- severity: ERROR|WARN|INFO
- from: ISO8601 timestamp
- to: ISO8601 timestamp
- keyword: string
- page: int (default: 0)
- size: int (default: 20)

Response (200 OK):
{
  "content": [
    {
      "logId": 12345,
      "timestamp": "2024-10-25T10:30:00Z",
      "serviceName": "user-service",
      "severity": "ERROR",
      "logContent": "...",
      "hasAnalysis": true
    }
  ],
  "page": {
    "size": 20,
    "totalElements": 1234,
    "totalPages": 62,
    "number": 0
  }
}
```

#### 3. ë¶„ì„ ê²°ê³¼ ì¡°íšŒ API

```
GET /api/v1/logs/{logId}/analysis
Authorization: Bearer <token>

Response (200 OK):
{
  "analysisId": 456,
  "logId": 12345,
  "bifrostAnalysisId": 789,
  "summary": "PostgreSQL ì—°ê²° íƒ€ì„ì•„ì›ƒ ë°œìƒ",
  "rootCause": "Connection pool ê³ ê°ˆ",
  "recommendation": "max_connections ì¦ê°€ ê¶Œì¥",
  "severity": "HIGH",
  "confidence": 0.95,
  "model": "mistral",
  "analyzedAt": "2024-10-25T10:30:15Z"
}
```

#### 4. í†µê³„ API

```
GET /api/v1/statistics
Authorization: Bearer <token>

Query Parameters:
- date: YYYY-MM-DD
- serviceName: string
- environment: string
- groupBy: hour|day|service

Response (200 OK):
{
  "period": {
    "from": "2024-10-25T00:00:00Z",
    "to": "2024-10-25T23:59:59Z"
  },
  "statistics": [
    {
      "timestamp": "2024-10-25T10:00:00Z",
      "serviceName": "user-service",
      "totalLogs": 1523,
      "bySeverity": {
        "ERROR": 45,
        "WARN": 234,
        "INFO": 1244
      },
      "avgSizeBytes": 512
    }
  ]
}
```

#### 5. í—¬ìŠ¤ì²´í¬ API

```
GET /actuator/health

Response (200 OK):
{
  "status": "UP",
  "components": {
    "db": {
      "status": "UP",
      "details": {
        "database": "PostgreSQL",
        "validationQuery": "SELECT 1"
      }
    },
    "kafka": {
      "status": "UP"
    },
    "elasticsearch": {
      "status": "UP"
    }
  }
}
```

### gRPC API (ì„ íƒì )

ê³ ì„±ëŠ¥ ë¡œê·¸ ìˆ˜ì§‘ì„ ìœ„í•œ gRPC ì¸í„°í˜ì´ìŠ¤:

```protobuf
syntax = "proto3";

package heimdall.v1;

service LogService {
  rpc IngestLog(LogIngestionRequest) returns (LogIngestionResponse);
  rpc StreamLogs(stream LogIngestionRequest) returns (stream LogIngestionResponse);
}

message LogIngestionRequest {
  string source = 1;
  string service_name = 2;
  string environment = 3;
  string severity = 4;
  string log_content = 5;
  map<string, string> metadata = 6;
  int64 timestamp_millis = 7;
}

message LogIngestionResponse {
  int64 log_id = 1;
  string event_id = 2;
  string status = 3;
}
```

---

## ğŸ”’ ë³´ì•ˆ ì•„í‚¤í…ì²˜

### ì¸ì¦/ì¸ê°€

```java
@Configuration
@EnableWebSecurity
public class SecurityConfig {
    
    @Bean
    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
        http
            .csrf().disable()
            .authorizeHttpRequests(auth -> auth
                .requestMatchers("/actuator/health").permitAll()
                .requestMatchers("/api/v1/**").authenticated()
                .anyRequest().denyAll()
            )
            .oauth2ResourceServer(oauth2 -> oauth2
                .jwt(jwt -> jwt.decoder(jwtDecoder()))
            );
        
        return http.build();
    }
    
    @Bean
    public JwtDecoder jwtDecoder() {
        // JWT ê²€ì¦ ë¡œì§
        return NimbusJwtDecoder.withJwkSetUri(jwkSetUri).build();
    }
}
```

### API Key ì¸ì¦

```java
@Component
public class ApiKeyFilter extends OncePerRequestFilter {
    
    @Override
    protected void doFilterInternal(
        HttpServletRequest request,
        HttpServletResponse response,
        FilterChain filterChain
    ) throws ServletException, IOException {
        
        String apiKey = request.getHeader("X-API-Key");
        
        if (apiKey != null && apiKeyService.validate(apiKey)) {
            // ì¸ì¦ ì„±ê³µ
            filterChain.doFilter(request, response);
        } else {
            response.sendError(HttpServletResponse.SC_UNAUTHORIZED);
        }
    }
}
```

### Rate Limiting

```java
@Component
public class RateLimitingInterceptor implements HandlerInterceptor {
    
    @Autowired
    private RateLimiter rateLimiter;
    
    @Override
    public boolean preHandle(
        HttpServletRequest request,
        HttpServletResponse response,
        Object handler
    ) throws Exception {
        
        String clientId = extractClientId(request);
        
        if (rateLimiter.tryAcquire(clientId)) {
            return true;
        } else {
            response.setStatus(HttpStatus.TOO_MANY_REQUESTS.value());
            return false;
        }
    }
}
```

---

## ğŸš€ ë°°í¬ ì „ëµ

### Docker ë°°í¬

```dockerfile
# Multi-stage build
FROM gradle:8-jdk17 AS builder
WORKDIR /app
COPY . .
RUN gradle clean build -x test

FROM eclipse-temurin:17-jre-alpine
WORKDIR /app
COPY --from=builder /app/build/libs/*.jar app.jar

EXPOSE 8080
ENTRYPOINT ["java", "-jar", "app.jar"]
```

### Kubernetes ë°°í¬

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: heimdall
spec:
  replicas: 3
  selector:
    matchLabels:
      app: heimdall
  template:
    metadata:
      labels:
        app: heimdall
    spec:
      containers:
      - name: heimdall
        image: heimdall:latest
        ports:
        - containerPort: 8080
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka:9092"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: heimdall-secrets
              key: database-url
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 20
          periodSeconds: 5
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
```

### HPA (Horizontal Pod Autoscaler)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: heimdall-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: heimdall
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„±

### Micrometer ë©”íŠ¸ë¦­

```java
@Configuration
public class MetricsConfig {
    
    @Bean
    public MeterRegistry meterRegistry() {
        return new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
    }
    
    @Bean
    public TimedAspect timedAspect(MeterRegistry registry) {
        return new TimedAspect(registry);
    }
}

@Service
public class LogIngestionService {
    
    @Autowired
    private MeterRegistry meterRegistry;
    
    @Timed(value = "log.ingestion", description = "Time to ingest log")
    public void ingestLog(LogEntry logEntry) {
        // ë¡œì§
        
        meterRegistry.counter("logs.ingested.total",
            "service", logEntry.getServiceName(),
            "severity", logEntry.getSeverity().name()
        ).increment();
    }
}
```

### ì£¼ìš” ë©”íŠ¸ë¦­

- `logs.ingested.total`: ìˆ˜ì§‘ëœ ë¡œê·¸ ìˆ˜
- `logs.processed.total`: ì²˜ë¦¬ëœ ë¡œê·¸ ìˆ˜
- `analysis.requested.total`: AI ë¶„ì„ ìš”ì²­ ìˆ˜
- `analysis.completed.total`: AI ë¶„ì„ ì™„ë£Œ ìˆ˜
- `kafka.consumer.lag`: Kafka consumer lag
- `db.connection.pool.size`: DB ì»¤ë„¥ì…˜ í’€ í¬ê¸°

---

**ë¬¸ì„œ ë²„ì „**: 1.0.0  
**ìµœì¢… ìˆ˜ì •**: 2024-11-11  
**ì‘ì„± ëª©ì **: Heimdall ê°œë°œíŒ€ ì•„í‚¤í…ì²˜ ê°€ì´ë“œ
